# @package _global_

task: eval
weight_model_path: ${model_type}
log_dir: './'
n_epochs: 1 #number of passes we make over the stream of documents to online adapt to. All experiments in the paper use 1 epoch
wandb_run_name: ${task}/${shorten_path:${weight_model_path}}/${shorten_path:${base_model}}/${notes}/${seed}-${uuid:}

bm_learned_layers: -1 #unused parameter which can be used to specify which layers of the base model are learned. -1 means all layers are learned
batch_size: 1
generation_batch_size: 1
grad_acc_steps: 1
grad_checkpointing: False

lr: .0001

#the following parameters are used in the uniform baseline with post-adaptation qa-tuning
qa_lt_final: False
lt_lr: 2.5e-5
lt_epochs: 0
lt_steps: 1000000
lt_val_steps: 16
lt_batch_size: 16
lt_grad_acc_steps: 4
lt_stopping_metric: 'max_f1'
lt_patience: 3

grad_clip_thresh: 750
downsample_to: -1 #if -1, we use the full dataset. Otherwise, we downsample to this number of documents

lt_early_stop: True
delete_checkpoints: True
eval_init: False
eval_every_k: -1 #if not -1, we evaluate every k steps
unrelated_qa_eval: False #if true, we also evaluate on the unrelated qa pairs


optimizer: 'adam'
eval: [em] #a list containing em, emK for integer K for top K evaluation, or 'ppl' to compute average answer token ppl/nll
num_beams: 12
num_beam_groups: 4
diversity_penalty: 10.0
notes: ''

subdir: 
hydra:
  job:
    chdir: true
  run:  
    dir: outputs/${task}/${dataset}/${model_type}-${shorten_path:${weight_model_path}}/${shorten_path:${base_model}}/${now:%Y-%m-%d}_${seed}_${uuid:}_${notes}
  sweep:
    dir: outputs/${task}/${dataset}/${model_type}-${shorten_path:${weight_model_path}}/${shorten_path:${base_model}}/${now:%Y-%m-%d}_${seed}_${uuid:}_${notes}
    subdir: ${hydra.job.num}
